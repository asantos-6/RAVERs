{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Dataset of Finger Tapping Single Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia\n",
    "import essentia.standard as estd\n",
    "import IPython\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from freesound import FreesoundClient\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [WIP] Retrieve Sounds from Freesound.org\n",
    "\n",
    "**this requires OAuth2 authentication**\n",
    "\n",
    "check this: https://gist.github.com/ffont/3607ba4af9814f3877cd42894a564222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREESOUND_API_KEY = \"t3Th3TkPGzn8z7cD45gyFtlSBpOpHIJVkItU3HU4\"\n",
    "tags = [\"finger-tapping\"]\n",
    "\n",
    "output_dir = \"../data/finger_tapping_downloads/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "api_key = FREESOUND_API_KEY\n",
    "if api_key is None:\n",
    "    print(\"You need to set your API key as an environment variable\")\n",
    "    print(\"named FREESOUND_API_KEY\")\n",
    "    sys.exit(-1)\n",
    "\n",
    "freesound_client = FreesoundClient()\n",
    "freesound_client.set_token(api_key)\n",
    "\n",
    "results_pager = freesound_client.text_search(query=\" \".join(tags), page_size=5)\n",
    "\n",
    "for sound in results_pager:\n",
    "    print(\"Downloading sound with id: %s\" % sound.id)\n",
    "    sound.retrieve(output_dir + sound.name + \".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onset-based Audio Segmentation with Essentia: Cutting and Saving Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/mono_kick_seq.wav\"\n",
    "\n",
    "audio = estd.MonoLoader(filename=filename)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compute the onset detection function\n",
    "od_hfc = estd.OnsetDetection(method='hfc')\n",
    "od_complex = estd.OnsetDetection(method='complex')\n",
    "\n",
    "# We need the auxilary algorithms to compute magnitude and phase.\n",
    "w = estd.Windowing(type='hann')\n",
    "fft = estd.FFT() # Outputs a complex FFT vector.\n",
    "c2p = estd.CartesianToPolar() # Converts it into a pair of magnitude and phase vectors.\n",
    "\n",
    "# # # Compute both ODF frame by frame. Store results to a Pool.\n",
    "pool = essentia.Pool()\n",
    "for frame in estd.FrameGenerator(audio, frameSize=1024, hopSize=512):\n",
    "    magnitude, phase = c2p(fft(w(frame)))\n",
    "    pool.add('odf.hfc', od_hfc(magnitude, phase))\n",
    "    pool.add('odf.complex', od_complex(magnitude, phase))\n",
    "\n",
    "# help(estd.FrameCutter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Detect onset locations.\n",
    "onsets = estd.Onsets()\n",
    "\n",
    "onsets_hfc = onsets(# This algorithm expects a matrix, not a vector.\n",
    "                    essentia.array([pool['odf.hfc']]),\n",
    "                    # You need to specify weights, but if we use only one ODF\n",
    "                    # it doesn't actually matter which weight to give it\n",
    "                    [1])\n",
    "\n",
    "onsets_complex = onsets(essentia.array([pool['odf.complex']]), [1])\n",
    "\n",
    "# Add onset markers to the audio and save it to a file.\n",
    "# We use beeps instead of white noise and stereo signal as it's more distinctive.\n",
    "\n",
    "# We want to keep beeps in a separate audio channel.\n",
    "# Add them to a silent audio and use the original audio as another channel. Mux both into a stereo signal.\n",
    "silence = [0.] * len(audio)\n",
    "\n",
    "beeps_hfc = estd.AudioOnsetsMarker(onsets=onsets_hfc, type='beep')(silence)\n",
    "beeps_complex = estd.AudioOnsetsMarker(onsets=onsets_complex, type='beep')(silence)\n",
    "\n",
    "audio_hfc = estd.StereoMuxer()(audio, beeps_hfc)\n",
    "audio_complex = estd.StereoMuxer()(audio, beeps_complex)\n",
    "\n",
    "# Write audio to files in a temporary directory.\n",
    "temp_dir = TemporaryDirectory()\n",
    "estd.AudioWriter(filename=temp_dir.name + '/tmp_onsets_hfc_stereo.mp3', format='mp3')(audio_hfc)\n",
    "estd.AudioWriter(filename=temp_dir.name + '/tmp_onsets_complex_stereo.mp3', format='mp3')(audio_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(temp_dir.name + '/tmp_onsets_hfc_stereo.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(temp_dir.name + '/tmp_onsets_complex_stereo.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n_frames = len(pool['odf.hfc'])\n",
    "frames_position_samples = np.array(range(n_frames)) * 512\n",
    "\n",
    "fig, ((ax1, ax2, ax3, ax4)) = plt.subplots(4, 1, sharex=True, sharey=False, figsize=(15, 16))\n",
    "\n",
    "ax1.set_title('HFC ODF')\n",
    "ax1.plot(frames_position_samples, pool['odf.hfc'], color='magenta')\n",
    "\n",
    "ax2.set_title('Complex ODF')\n",
    "ax2.plot(frames_position_samples, pool['odf.complex'], color='red')\n",
    "\n",
    "ax3.set_title('Audio waveform and the estimated onset positions (HFC ODF)')\n",
    "ax3.plot(audio)\n",
    "for onset in onsets_hfc:\n",
    "    ax3.axvline(x=onset*44100, color='magenta')\n",
    "\n",
    "ax4.set_title('Audio waveform and the estimated onset positions (complex ODF)')\n",
    "ax4.plot(audio)\n",
    "for onset in onsets_complex:\n",
    "    ax4.axvline(x=onset*44100, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../data/output_onsets/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Convert numpy float32 arrays to Python lists\n",
    "onset_times_hfc_list = list(onsets_hfc)\n",
    "onset_times_complex_list = list(onsets_complex)\n",
    "\n",
    "# Function to cut audio around each onset\n",
    "def cut_audio_around_onsets(audio, onset_times, output_dir):\n",
    "    for i, onset_time in enumerate(onset_times):\n",
    "        start_time = max(0, onset_time - 0.2)  # 200 ms before the onset\n",
    "        end_time = onset_times[i + 1] if i + 1 < len(onset_times) else len(audio)\n",
    "        end_time = min(len(audio), end_time + 0.2)  # 200 ms before the next onset\n",
    "\n",
    "        # Extract the portion of audio\n",
    "        onset_audio = audio[int(start_time * 44100):int(end_time * 44100)]\n",
    "\n",
    "        # Save the onset audio to a file\n",
    "        output_filename = os.path.join(output_dir, f'onset_{i + 1}.wav')\n",
    "        estd.AudioWriter(filename=output_filename, format='wav')(onset_audio)\n",
    "\n",
    "# Cut audio around onsets for both methods\n",
    "cut_audio_around_onsets(audio_hfc, onset_times_hfc_list, output_dir)\n",
    "cut_audio_around_onsets(audio_complex, onset_times_complex_list, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
