{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio(audio, sr, ti, tf, mono=True):\n",
    "    i = ti * sr\n",
    "    f = tf * sr\n",
    "    if mono:\n",
    "      t_audio = audio[i:f]\n",
    "    else:\n",
    "      t_audio = audio[:, i:f]\n",
    "    return t_audio\n",
    "\n",
    "def read_audio(file_path, trim_interval=None, mono=True, print_it=False):\n",
    "    audio, sr = librosa.load(file_path, mono=mono)\n",
    "    audio_dim = len(audio.shape)\n",
    "    if not mono and audio_dim == 1:\n",
    "      audio = np.asarray((audio, audio))\n",
    "    if trim_interval is not None:\n",
    "      ti = trim_interval[0]\n",
    "      tf = trim_interval[1]\n",
    "      audio = trim_audio(audio, sr, ti, tf, mono)\n",
    "    if print_it:\n",
    "      print(audio.shape)\n",
    "      print(sr)\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder_path = '../data/WAV/Individual Hits/02. Snare Drum/01. Clean'\n",
    "\n",
    "model_path = '../models/drumkit_v1.ts'\n",
    "model = torch.jit.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latent_spaces = []\n",
    "\n",
    "for audio_file in os.listdir(audio_folder_path):\n",
    "  if not audio_file.endswith('.wav'): continue\n",
    "  audio, sr = read_audio(f'{audio_folder_path}/{audio_file}')\n",
    "  ipd.Audio(audio, rate=sr)\n",
    "  with torch.no_grad():\n",
    "    x = torch.from_numpy(audio).reshape(1,1,-1)\n",
    "    z = model.encode(x)\n",
    "    latent_space = torch.squeeze(z, 0)\n",
    "    latent_space_np = latent_space.numpy()\n",
    "    latent_spaces.append(latent_space_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results.points, columns=['x', 'y'])\n",
    "df['label'] = dataset.values('label')\n",
    "df['audio_name'] = dataset.values('audio_name')\n",
    "df['filepath'] = dataset.values('filepath')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "# Create a scatter plot of the latent space\n",
    "data = []\n",
    "for label in df['label'].unique():\n",
    "    df_label = df[df['label'] == label]\n",
    "    scatter = go.Scatter(\n",
    "        x=df_label['x'], \n",
    "        y=df_label['y'], \n",
    "        mode='markers',\n",
    "        text=df_label['audio_name'],  # Add the audio name as text\n",
    "        hovertemplate='%{text}<extra></extra>',  # Customize the hover template\n",
    "        name=label,  # Use the label as the name of the trace\n",
    "        customdata=df_label['filepath']  # Add the file path as custom data\n",
    "    )\n",
    "    scatter.on_click(lambda x: print(x.points[0].hovertext))  # Print the name of the point when it's clicked\n",
    "    data.append(scatter)\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "# Adjust the margins (l, r, t, b stand for left, right, top, and bottom)\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=400,\n",
    "    margin=dict(l=24,r=24,b=24,t=24,pad=0)\n",
    ")\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import base64\n",
    "import io\n",
    "\n",
    "def get_relative_path(absolute_path):\n",
    "    base_path = os.getcwd()\n",
    "    return os.path.relpath(absolute_path, base_path)\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id='scatter-plot', figure=fig),\n",
    "    html.Pre(id='click-data', style={'padding': '10px', 'color': 'white'}),\n",
    "    html.Audio(id='input-player', controls=True, autoPlay=True),\n",
    "    html.Audio(id='output-player', controls=True, autoPlay=False)\n",
    "])\n",
    "\n",
    "@app.callback(Output('click-data', 'children'), [Input('scatter-plot', 'clickData')])\n",
    "def display_click_data(clickData):\n",
    "    if clickData is None: return 'None'\n",
    "    absolute_path = clickData[\"points\"][0][\"customdata\"]\n",
    "    base_path = os.getcwd()\n",
    "    return os.path.relpath(absolute_path, base_path)\n",
    "\n",
    "@app.callback(Output('input-player', 'src'), [Input('scatter-plot', 'clickData')])\n",
    "def play_input(clickData):\n",
    "    if clickData is None: return ''\n",
    "\n",
    "    relative_path = get_relative_path(clickData[\"points\"][0][\"customdata\"])\n",
    "    with open(relative_path, 'rb') as audio_file:\n",
    "        encoded_audio = base64.b64encode(audio_file.read()).decode('ascii')\n",
    "    src = f'data:audio/mp3;base64,{encoded_audio}'\n",
    "    \n",
    "    return src\n",
    "\n",
    "@app.callback(Output('output-player', 'src'), [Input('scatter-plot', 'clickData')])\n",
    "def play_output(clickData):\n",
    "    if clickData is None: return ''\n",
    "    \n",
    "    relative_path = get_relative_path(clickData[\"points\"][0][\"customdata\"])\n",
    "\n",
    "    audio, sr = read_audio(relative_path)\n",
    "    with torch.no_grad():\n",
    "        x = torch.from_numpy(audio).reshape(1 ,1, -1)\n",
    "        z = model.encode(x)\n",
    "        x_hat = model.decode(z)\n",
    "    waveform_tensor = torch.squeeze(x_hat, 0)\n",
    "    output_path = '../output/output.wav'\n",
    "    torchaudio.save(output_path, waveform_tensor, sr)\n",
    "\n",
    "    with open(output_path, 'rb') as audio_file:\n",
    "        encoded_audio = base64.b64encode(audio_file.read()).decode('ascii')\n",
    "    src = f'data:audio/mp3;base64,{encoded_audio}'\n",
    "\n",
    "    return src\n",
    "\n",
    "if __name__ == '__main__': app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raversenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
